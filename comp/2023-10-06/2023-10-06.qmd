---
title: Proposal
date: '2023-10-06'
date-format: long
description: <em>My project proposal.</em>
toc: true
page-layout: full
bibliography: sources.bib
nocite: "`\\nocite{*}`{=latex}"
---

**Development of Quadcopter for Autonomous Navigation and Exploratory
Design of Solid State LiDAR**

Simon J. Jones  
Daniel Willey, PhD  
Janyl Jumadinova, PhD

Fall 2023

*Department of Physics*  
*Department of Computer and Information Science*  
*Allegheny College, Meadville, PA 16335*

**ABSTRACT**

Here I propose a two-sided project involving the development of a
quadcopter capable of autonomous navigation and the exploratory
prototype design of a solid state Light Detection and Ranging (LiDAR)
system. Many autonomous systems rely on ranging sensors to determine the
relative position of obstacles while navigating. LiDAR has numerous
applications in robotics, autonomous navigation, and surveying. LiDAR
sensor data can be used alone or in tandem with camera data to perform
spatial mapping of a robot’s environment. (Raj et al. 2020) Research in
the past decade has made the field of Deep Reinforcement Learning (DRL)
infamous for its reduced need for sample data. (Zhu and Zhang 2021) DRL
has shown strong potential, especially for autonomous navigation.
(Hodge, Hawkins, and Alexander 2021) We plan to train a quadcopter for
autonomous navigation using a DRL algorithm. The quadcopter will be
equipped with a sequence of Time-of-Flight (ToF) sensors as a LiDAR
system. Because LiDAR systems are increasingly becoming solid-state,
meaning they omit the use of mechanical processes to scan their
surroundings,(Li et al. 2022) we will also be exploring the novel design
of a solid-state LiDAR component for beam deflection by using a nematic
Liquid Crystal (LC). We will measure our success by the effectiveness of
the quadcopter to navigate through increasingly restricted environments
and how large of an angle the LiDAR system can deflect a light source.
Additionally, we will compare our results to similar work done in the
literature to evaluate our approach to training the quadcopter as well
as our implementation of the LiDAR component.

## INTRODUCTION & BACKGROUND

Robotic navigation is the ability of an autonomous system to determine a
course of action to avoid colliding with an obstacle. Navigation is
necessary for a robot to interact with a real world scenario and to
realize technologies such as fully autonomous vehicles. Modern robotics
use either ranging sensors (acoustic or optical) or camera information
to interpret the relative position of obstacles; however, interpreting
reliable and fast 3D spatial data via a camera, called optical flow,
requires extensive training and large amounts of data. Although recent
work has enabled a racing quadcopter to outperform professional pilots,
boasting a speed of $22\frac{\text{m}}{\text{s}}$ using only an
optical flow model, training a model from ranging sensor data is much
simpler compared to that of system using a camera for image-based
ranging, which is important when considering the feasibility of this
project. (Song et al. 2023) Ranging sensors can supply scalar
interpretations of the distance between the sensor and the obstacle.
Supplying an array of spatial measurements in the form of a tensor can
be used to train a machine learning model capable of avoiding collisions
while navigating a robot. In the past decade, Deep Reinforcement
Learning (DRL) has emerged as a viable form of unsupervised learning
that allows a model to adapt itself by comparing its performance to a
base metric that defines ‘good’ and ‘bad’ results. (Zhu and Zhang 2021)
Recently, it has been shown that combining DRL with other learning
algorithms has prevented the learning process from tending toward a
local minima rather than the desired global minima. (Hodge, Hawkins, and
Alexander 2021)

Touching back on the usage of ranging sensors, advances in laser diode
technology over the last two decades have yielded the miniaturization
and affordability of the Vertical Cavity Surface Emitting Laser (VCSEL).
Hundreds of these diodes can be manufactured on a single silicon wafer,
which has allowed them to be mass produced and used in consumer
electronics such as cell phones. Naturally, multiple LiDAR systems have
opted to use VCSEls because of their size and price. (Raj et al. 2020;
Iga 2000)

Many current LiDAR systems either rely on mechanical processes or having
an array of laser diodes to determine spatial data. This leads to
bulkier systems with a higher chance of mechanical failure. Solid-state
LiDAR systems mitigate these issues by nature of their design. (Li et
al. 2022) Modern implementations of solid-state LiDAR use metamaterials
or microelectromechanical (MEMS) systems to achieve tunable beam
deflection. These systems rely on extremely precise manufacturing
processes, which are expensive and time consuming.

<figure>
<img src="images/liquidCrystalBeamSteering.png" id="fig:lcbeamsteering"
style="width:30.0%"
alt="Three layers of nematic liquid crystals used to deflect a light source.(Zhang et al. 2023)" />
<figcaption aria-hidden="true">Three layers of nematic liquid crystals
used to deflect a light source.<span class="citation"
data-cites="zhang2023">(Zhang et al. 2023)</span></figcaption>
</figure>

<figure>
<img src="images/lcelectricfield.png" id="fig:lcelectricfield"
style="width:70.0%"
alt="Behavior of nematic liquid crystal cell under applied voltage. Inner molecules align strongest with the electric field, while they align more closely to the orientation of the molecules at the surface as they tend to the surface. (Cirtoaje 2021)" />
<figcaption aria-hidden="true">Behavior of nematic liquid crystal cell
under applied voltage. Inner molecules align strongest with the electric
field, while they align more closely to the orientation of the molecules
at the surface as they tend to the surface. <span class="citation"
data-cites="cirtoaje2021">(Cirtoaje 2021)</span></figcaption>
</figure>

Liquid crystals are materials with a repeated molecular structure
capable of being influenced by external factors such as chemical
treatment or applied electric fields. Photons interacting with a liquid
crystal interface will be refracted depending on their polarization.
(Cirtoaje 2021) Because the liquid crystal molecules each form an
electric dipole, they orient themselves along an applied electric field
as seen in Fig. <a href="#fig:lcelectricfield" data-reference-type="ref"
data-reference="fig:lcelectricfield">2</a> Research has shown that
sub-mm layers of nematic liquid crystals can be used to achieve beam
deflection at large angles when stacked upon each other. (Zhang et al.
2023) Fig. <a href="#fig:lcbeamsteering" data-reference-type="ref"
data-reference="fig:lcbeamsteering">1</a> illustrates such a
configuration. This research demonstrates that nematic liquid crystals
(of a nematic molecular pattern) could be a cheaper and perhaps more
viable method of realizing solid-state LiDAR.

## PROPOSED EXPERIMENTAL DETAILS

The chosen quadcopter platform is the drone, which uses open source
software, ideal for our purpose. (“COEX Clover,” n.d.) The Clover can be
integrated with any sensor thanks to its on-board Raspberry Pi 4 (RPi4);
thus, we will opt to use an array of ToF sensors to measure spatial
data. This is, by definition, a LiDAR system. The Clover supports the
MAVROS protocol, which permits a communication channel between the
on-board computer (RPi4) and the drone’s flight controller. The Clover
also supports the *Robotic Operating System* (ROS), which is a
collection of software and methodologies that generalize robotics
development. (Stanford Artificial Intelligence Laboratory et al., n.d.)

<figure>
<img src="images/clover.png" id="fig:clover" style="width:40.0%"
alt="COEX Clover quadcopter. (“COEX Clover,” n.d.)" />
<figcaption aria-hidden="true">COEX Clover quadcopter. <span
class="citation" data-cites="clover">(<span>“COEX Clover,”</span>
n.d.)</span></figcaption>
</figure>

We will start by simulating runs of the Clover using *Gazebo*, a visual
simulation program compatible with ROS. (Robotics, n.d.) Gazebo has a
built-in physics engine, and, COEX has supplied documentation outlining
how to simulate the Clover using this tool. We will then begin to
integrate DRL into this process in order to discover ways to effectively
train a model for navigation. During this stage, we will review more
literature on DRL and develop a deeper understanding of the mathematics
behind DRL.

As our simulations reach observable consistency, we will then consider
running this model on a real-time system. This will certainly produce
unexpected results, with various factors such as fluctuations in air
viscosity and wind currents capable of skewing the expected behavior of
a model. We will most likely spend time troubleshooting the model’s
control loop so that it can handle real-world conditions during this
time.

Once we have a model that consistently controls the quadcopter outside
of a simulation, we will focus on training the model to navigate
increasingly complex environments. This will most likely be doing using
iterations of arbitrary 3D shapes in a simulation. We plan to use sheets
of cardboard, or some other cheap material, to create obstacles to use
in our testing.

Regarding the LiDAR prototype, we plan to either use physical nematic
liquid crystals (LCs) or simulate such an interaction between light and
matter. If we are to use physical nematic LCs, we will need to either
purchase them or fabricate our own. Given that the nonlinear optics lab
has been left in a condition making it extremely difficult to work in,
we are considering a simulation-based approach as a way to avoid the
overhead of cleaning this lab in order to use it. Nevertheless, we will
explore the physics of nematic liquid crystals, specifically
investigating their birefringent properties through literature,
experimentation, or simulation. After we have developed a solid
understanding of how to steer an incident light source through a liquid
crystal, we will begin to design a novel optical system that could be
used as a component of a LiDAR system.

## MEASURE OF SUCCESS

During the final stages of this project, we will evaluate the
effectiveness of the quadcopter in its ability to navigate through
random configurations of obstacles in comparison with results found in
the literature. We will first need to determine a metric for calculating
what defines the navigability of a space. Then, we will be able to view
the performance of the model with respect to the navigabililty metric to
provide a quantitative evaluation of our model.

Additionally, we will look at the features of our LiDAR system to
evaluate quantitative results such as maximum angle of deflection, the
rate at which it could potentially measure its surroundings, and the
argument that it poses as a viable technology for use in solid-state
LiDAR. Potential hurdles to a successful prototype could take the form
of the following:

1.  Difficulty in preparing the LC samples to conform to a specific
    molecular configuration pattern.

2.  A slow response time for the molecules to align to an applied
    magnetic field, considering that transition time is a function of
    the thickness of the sample. This could negatively affect the rate
    at which a LiDAR system could measure its surroundings if it
    exhibits a slow response time. (Cirtoaje 2021)

3.  Finding a coherent infrared light source
    $(\lambda \approx 800-900\rm{nm})$.

## CONCLUSION

Autonomous systems capable of navigation will be integral to a society
based upon autonomous transportation and delivery. Exploring a current
approach to training an autonomous system will allow me to shape my
understanding of DRL and form a basis for working with other advanced
techniques of machine learning. Future students will be able to use the
COEX Clover to do similar work as the field evolves, as this provides
another platform for students to engage in robotics at Allegheny. As
solid-state LiDAR technology develops, it is important to evaluate
implementations in terms of their cost, fabrication techniques, and
effect on the environment. Creating a solid-state LiDAR that uses less
exotic materials and smaller components will not only make LiDAR a more
accessible technology but also less harmful to the environment.

Finally, the aim of this project is to explore and evaluate the use of
LiDAR sensing in the current era of robotics. Although robotics is
growing rapidly, these principles will be applicable for decades ahead,
and this will work will benefit not only myself but also future students
at Allegheny with an interest in autonomous systems.

**BIBLIOGRAPHY**

Bogatov, N, A Kostin, and N Maiorov. 2021. “Control and Analysis of
Quadcopter Flight When Setting a Complex Trajectory of Motion.” In
*Journal of Physics: Conference Series*, 1925:012043. 1. IOP Publishing.

Cirtoaje, Cristina. 2021. “Ferroelectric Particles in Nematic Liquid
Crystals with Soft Anchoring.” *Molecules* 26 (4).
<https://doi.org/10.3390/molecules26041166>.

“COEX Clover.” n.d. <https://clover.coex.tech/en/>.

Hodge, Victoria J, Richard Hawkins, and Rob Alexander. 2021. “Deep
Reinforcement Learning for Drone Navigation Using Sensor Data.” *Neural
Computing and Applications* 33: 2015–33.

Iga, Kenichi. 2000. “Surface-Emitting Laser-Its Birth and Generation of
New Optoelectronics Field.” *IEEE Journal of Selected Topics in Quantum
Electronics* 6 (6): 1201–15.

Koyama, Fumio. 2014. “Advances and New Functions of VCSEL Photonics.”
*Optical Review* 21: 893–904.

Li, Nanxi, Chong Pei Ho, Jin Xue, Leh Woon Lim, Guanyu Chen, Yuan Hsing
Fu, and Lennon Yao Ting Lee. 2022. “A Progress Review on Solid-State
LiDAR and Nanophotonics-Based LiDAR Sensors.” *Laser & Photonics
Reviews* 16 (11): 2100511.

Mur, Urban, Miha Ravnik, and David Seč. 2022. “Controllable Shifting,
Steering, and Expanding of Light Beam Based on Multi-Layer
Liquid-Crystal Cells.” *Scientific Reports* 12 (1): 352.

Raj, Thinal, Fazida Hanim Hashim, Aqilah Baseri Huddin, Mohd Faisal
Ibrahim, and Aini Hussain. 2020. “A Survey on LiDAR Scanning
Mechanisms.” *Electronics* 9 (5): 741.

Robotics, Open. n.d. “Gazebo.” <https://gazebosim.org/home>.

Saleh, Bahaa EA, and Malvin Carl Teich. 2019. *Fundamentals of
Photonics*. John Wiley & sons.

Sciortino, Claudio, and Adriano Fagiolini. 2018. “ROS/Gazebo-Based
Simulation of Quadcopter Aircrafts.” In *2018 IEEE 4th International
Forum on Research and Technology for Society and Industry (RTSI)*, 1–6.
IEEE.

Song, Yunlong, Angel Romero, Matthias Müller, Vladlen Koltun, and Davide
Scaramuzza. 2023. “Reaching the Limit in Autonomous Racing: Optimal
Control Versus Reinforcement Learning.” *Science Robotics* 8 (82):
eadg1462.

Stanford Artificial Intelligence Laboratory et al. n.d. “Robotic
Operating System.” <https://www.ros.org>.

Zhang, Guanxiong, Steve J Elston, Andy Schreier, Grahame Faulkner,
Atchutananda Surampudi, Dominic O’Brien, and Stephen M Morris. 2023.
“Non-Mechanical Optical Beam-Steering of a Liquid Crystal Laser.”
*Optics & Laser Technology* 157: 108623.

Zhu, Kai, and Tao Zhang. 2021. “Deep Reinforcement Learning Based Mobile
Robot Navigation: A Review.” *Tsinghua Science and Technology* 26 (5):
674–91.
