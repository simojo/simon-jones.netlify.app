---
title: "Professional Précis"
subtitle: "Author: Simon Jones"
---

# About the Author

I'm a senior at Allegheny College studying Computer Science and Physics.

![](me.jpg)

# Week 1

# Week 2

## SE1: Preface - Programming Over Time

#### Summary

In the preface of *Software Engineering at Google*, the section [Programming Over Time](https://abseil.io/resources/swe-book/html/pr01.html#programming_over_time) defines software engineering as "programming integrated over time." The purpose of the book is to answer reflective questions that Software Engineering (SWE) teams should have during the life cycle of a project and a company or institution. The thesis of the book is then laid out as motivated by three principles that should be held in the development process: **Time and Change**, **Scale and Growth**, and **Trade-offs and Costs**.

* **Time and Change** refers to how a codebase or stack adapts over the lifetime of a team or company.
* **Scale and Growth** refers to the need for an organization to adjust its practices and structure over the lifetime of a team or company.
* **Trade-offs and Costs** refers to how an organization analyzes historical data to make informed decisions from the previous two points.

#### Action Items & Reflection

* **Start doing:** In my professional and personal SWE experience, this reading reminds me that I need to be aware of the changes in the people and settings around me in order to be an amiable colleague. Paying attention to the culture that surrounds the work environment will be something that I will try to work on.
* **Stop doing:**I should also make steps towards stopping holding a certain attitude towards the tooling used in class. Software is about *adapting* to changes rather than resisting them. That said, one should maintain a discerning attitude when acquiring new tooling to avoid being distracted by its 'shininess.'
* **Keep doing:** As long as cs203 continues to meet regularly and heavily rely on the issue tracker, we will proceed to evolve as a group and reach an efficient workflow.

## FB1: Introduction to Software Testing

#### Summary

The chapter **Introduction to Software Testing** in the Fuzzing Book walks us through the most fundamental idea of what software testing looks like, starting from the most basic example of a square root finder that finds only real roots $(f : \mathbb{R}^+ \to \mathbb{R}^+)$. We are presented with the idea of proving the said function's correctness by a single example input; however we find the more general approach of verifying the function's result thanks to the fact that $\sqrt{x}*\sqrt{x}=x$ for all $x \in \mathbb{R}$. We can do this for any number, say 2, to demonstrate:

```{python}
def my_sqrt(x):
    """Computes the square root of x, using the Newton–Raphson method"""
    approx = None
    guess = x / 2
    while approx != guess:
        approx = guess
        guess = (approx + x / approx) / 2
    return approx

# does this *really* equal 2 exactly? Probably not
print(my_sqrt(2) * my_sqrt(2))
```

But, this manual approach becomes painful after writing even a small amount. The book then informs us of automating test execution, in which expected results are stored in values and checked against the actual result, throwing an error if they do not match. The only limitation with this is that python's numeric types rarely are exactly equal up to a certain precision. To flush this problem, the book explains that a potential solution could use a pre-set margin of error to ensure the result is within its bounds, or to simply use `math.isclose()`, which apparently is the way of a true *pythonista*.

More automated methods of testing are discussed, including timing execution time of iterated tests:

```{python}
import time
EPSILON = 1e-8 # apparently good margin of error (don't take my word for it, ask Andreas Zeller)
start = time.time()
for i in range(1, 1000):
  assert (my_sqrt(i) * my_sqrt(i) - i) < EPSILON
print(time.time() - start)
```

Additionally, the book mentions opting for a range of randomly selected numbers to be used rather than incremental cases, which ensures an even distribution of numbers. The only caveat is that edge cases, also called counter examples, are found with a probability of roughly one in one million (e.g. 0). This idea brings us to the final one mentioned in this article, which is *the limits of testing*.

**The limits of testing** are that testing, as with any conjecture in a software setting, can never be 100% deterministic of correct results. Tests only go so far to ensure input will translate to a correct output, but they are the best weapon we as developers have to avoid runtime errors.

#### Action Items & Reflection

* **Start doing:** I plan to keep up with the test cases that we will be implementing in `chasten` this year. This will be a good idea because of the variety of developers we will have working on the project. I previously would never write test cases, but now that our development team is so large, I see this as a must. This will allow developers to add tests to eliminate the possibility of a certain function leading to a bug later in the development process.
* **Stop doing:** `null`
* **Keep doing:** The `chasten` team should, as a whole, continue to keep the discussion of the importance of testing in the foreground and collectively discuss how we can begin to approach test case creation for the more complex objects we will be working with this semester.

# Week 3

## SE2: What is Software Engineering?

#### Summary

In the chapter *What is Software Engineering?* of the [Software Engineering at Google Book](https://abseil.io/resources/swe-book/html/pr01.html), the author outlines the importance of developing structured behavior to succeed in a software engineering environment. Firstly, many of the responsibilities in SWE are because of **long-term project management**. SWE principles are less important for a project that will be used for a shorter lifespan. Good practices can lead to a sustainable project, meaning that the project is able to react and adopt valuable changes during its life span.

Technical debt and the cost of finesse are two things that negatively affect the health of a codebase. As said in this chapter: "We’ve taken to saying, “It’s programming if 'clever' is a compliment, but it’s software engineering if 'clever' is an accusation.”" 'Clever' work is seldom obvious and maintainable, which is why it harms a long lived system. If, for example, a side effect of some 'clever' code produced an unexpected behavior on the user-side, the user could begin to rely on that functionality *without realizing it was done unintentionally*. This idea is known as **Hyrum's Law**, which states that all observable behaviors in your tool will be relied on my some entity. A way to fight against technical debt is to implement scalability, which allows a codebase to be supported properly as it grows (i.e. the company grows with the code base). Weak points in scalability can be discovered by asking *"Does my organization have a procedure in place to grow the amount of man power when the codebase or workload grows?"* If the answer is no, then there is a high chance you have a scaling problem.

Cost is a large factor in decision making, and this chapter briefly discusses its weight. There are various costs associated with decision making in SWE. Some of which are:

* Financial costs (e.g., money)
* Resource costs (e.g., CPU time)
* Personnel costs (e.g., engineering effort)
* Transaction costs (e.g., what does it cost to take action?)
* Opportunity costs (e.g., what does it cost to not take action?)
* Societal costs (e.g., what impact will this choice have on society at large?)

Being able to weight cost effectively is a tool used in leadership. Google's example of effective cost analysis is the ironic value of markers in a work place setting. Markers are cheap, but they are often found missing or dried up in meeting rooms. Google weighed the cost of constantly supplying markers to their employees against the flow of a meeting or brainstorming session being brought to a halt, and they decided it was better to yield a free flowing brainstorming session than to pay the price for regularly new markers. The decision has proven to do them well.

#### Action Items & Reflection

* **Start doing:** From this reading, I recognize our development team should spend more time focusing on structure, at least in the first few weeks, to permit a steady workflow by the end of the semester.
* **Stop doing:** N/A
* **Keep doing:** We should keep regularly critiquing our process. For example, on Monday 2023-09-11 in our class session, we revised our process slightly, and I believe it was a great decision to split up work the way that we did.

## FB2: Coverage

#### Summary

In this chapter, we learn about black and white box testing. Black box testing allows us to test the *specified* behavior of a system, while white box testing focuses on revealing which part in the internal structure of the program went wrong during the testing process. Both have their beneifts, but generally white-box testing allows us to debug more easily. In assisting white-box testing, we can use `sys.settrace(f(frame, event, arg))` to trace the execution of the function. This provides us with the lines that are stepped through during program execution. These lines are then put into a set, which tells us the lines that have been covered *at least* once.

We can also compare coverage between various test cases, which can provide a different aspect of code usage based on input. If you incorporate fuzzing into this, you could input every possible kind of data type in a function to test how the branches are covered statistically. If you discover a branch that never is covered for all iterations of fuzzing, then you have a serious issue! This is just one example of the many benefits of code coverage used in tandem with fuzzing.

#### Action Items & Reflection

* **Start doing:** After we discuss this in class, we should all make it a point to include coverage analysis in `chasten` so that we only save the necessary code we have. In the branch I am currently working on, I will look into see if this is a possibility.
* **Stop doing:** N/A
* **Keep doing:** We should keep regularly talking about principles like these. It helps keep us all on the same page as to where we should be headed as a development team.

# Week 4

## SE3: How to Work Well on Teams

#### Summary

The chapter [How to Work Well on Teams](https://abseil.io/resources/swe-book/html/ch02.html) in the [Software Engineering at Google Book](https://abseil.io/resources/swe-book/html/toc.html) encourages healthy co working culture. The first principle to understand is that geniuses are never completely self made; every successful leader has had to work collaboratively at some point. The misconception that hard working individuals only get work done alone is a myth. It creates insecurity and sends narcissists on their own joy ride of self sufficiency (think about the connotations of "10x developer", for example). Too much lone ranger-esque coding in your company could lead to a higher bus factor: the number of people that need to get bit by a bus before your project is completely doomed.

Through team work, we must not only work collaboratively, but seek to encourage each other through correction and review.

> In a professional software engineering environment, criticism is almost never personal—it’s usually just part of the process of making a better project.  The trick is to make sure you (and those around you) understand the difference between a constructive criticism of someone’s creative output and a flat-out assault against someone’s character.

It is very easy to get offended from hearing that your work is not up-to-par. Supervisors and peers should be mindful of how they are leveraging their position of knowledge over those that they are helping.

I understand the consequences of individual based work in a company. I have worked with individuals where, if they were hit by a bus, the company would surely have lost hundreds of thousands of dollars over the course of a week. We were a team of four people, and each of us kept strictly to our own little feature sets and subset of our main stack. Although it can be tempting to take matters into one's own hands and micromanage or even take complete control of a project, I will steer clear of this in my future career, regardless of the position.

I would like to spend time analyzing our conflicts that we have had in class in order to understand the minds of my peers more. Looking back and thinking about our class discussions, I can definitely tell that some people in the class perform better when telling others what to do, while some people perform better while being told what to do. This dynamic is something that will have to discover together as a team.

As it stands, it is a good practice that we write up incident reports. This was mentioned in the book, and we have already written an incident report concerning a minor issue we had. Although painful, this fosters responsibility and awareness of mistakes towards a collective awareness.

#### Action Items & Reflection

* **Start doing:** Paying attention to my interactions with team members and noting what personality types are in the room around me.
* **Stop doing:** Working on feature branches strictly alone, or at least not writing *completely* indicative test cases that describe the intended functionality of my code.
* **Keep doing:** Writing out incident reports; although painful, those are helpful and help us to constructively criticize ourselves.

## FB3: Fuzzing: Breaking Things with Random Inputs

#### Summary

This chapter in the Fuzzing Book, **Fuzzing: Breaking Things with Random Inputs**, explains the more specific details of fuzzing and even provides some examples of fuzzing implementations. We are familiarized with the concept of a `Runner`, which is usually a class responsible for managing the testing of function inputs. We also learn about the origins of fuzzing, which came from a lab in UW-Madison during a thunderstorm, when interference coming through the phone lines falsely sent information to programs. The fuzziness of the random input from the phone lines was dubbed 'fuzzing', as we know it today.

Through reading this chapter, I certainly feel overwhelmed by the complexities of fuzzing. I do wish to continue to add fuzzing test cases to programs that we create, though. I have already implemented a few in my feature branch. The biggest hurdle in this is the use of `hypothesis`, a python library. It is fairly complex, and it requires thorough reading of its documentation to fully understand it.

#### Action Items & Reflection

* **Start doing:** Reading through the documentation of `hypothesis` in order to better implement fuzzing strategies in the `tests/` for chasten.
* **Stop doing:** N/A
* **Keep doing:** Trying to implement test cases in every feature branch.

# Week 5

## SE4: Knowledge Sharing

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB4: Mutation Analysis

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 6

(Executable Examination)

# Week 7

## SE5: Engineering for Equity

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB5: Mutation-Based Fuzzing

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 8

## SE6: How to Lead a Team

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB6: Fuzzing with Grammars

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 9

## SE7: Leading at Scale

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB7: Efficient Grammar Fuzzing

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 10

## SE8: Style Guides and Rules

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB8: Parsing Inputs

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 11

(Executable Examination)

# Week 12

## SE9: Code Review

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## FB9: Reducing Failure-Inducing Inputs

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 13

## SE10: Documentation

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## DB1: Introduction to Debugging

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 14

## SE11: Testing Overview

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## DB2: Tracing Executions

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 15

## SE12: Unit Testing

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## DB3: Assertions

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

# Week 16

## DB4: Statistical Debugging (Automatic Fault Localization)

#### Summary

#### Action Items & Reflection

* **Start doing:**
* **Stop doing:**
* **Keep doing:**

## Final review of all content on Developer Development web site

Final exam for this class is December 14, 2023 at 09:00
